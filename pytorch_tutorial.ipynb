{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa3e6f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch.optim as optim\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fa382a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: torch.Size([455, 30]) and torch.Size([455, 1])\n",
      "Test: torch.Size([114, 30]) and torch.Size([114, 1])\n",
      "iter: 1 loss=0.6931472420692444\n",
      "iter: 101 loss=0.6931472420692444\n",
      "iter: 201 loss=0.6931472420692444\n",
      "iter: 301 loss=0.6931472420692444\n",
      "iter: 401 loss=0.6931472420692444\n",
      "iter: 501 loss=0.6931472420692444\n",
      "iter: 601 loss=0.6931472420692444\n",
      "iter: 701 loss=0.6931472420692444\n",
      "iter: 801 loss=0.6931472420692444\n",
      "iter: 901 loss=0.6931472420692444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "\n",
    "torch.manual_seed(1331)\n",
    "\n",
    "data = load_breast_cancer()\n",
    "\n",
    "X = torch.tensor(data.data, dtype=torch.float32)\n",
    "y = torch.tensor(data.target, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "n = int(len(X)*0.8)\n",
    "\n",
    "X_train = X[:n]\n",
    "X_test = X[n:]\n",
    "y_train = y[:n]\n",
    "y_test = y[n:]\n",
    "\n",
    "print(f\"Train: {X_train.shape} and {y_train.shape}\")\n",
    "print(f\"Test: {X_test.shape} and {y_test.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "class MiniNeuron(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(X_train.shape[1], X_train.shape[1]),\n",
    "            nn.Linear(X_train.shape[1], 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n",
    "    \n",
    "# training the MLP\n",
    "model = MiniNeuron()\n",
    "\n",
    "critation = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 1000\n",
    "eval_interval = epochs * 0.1\n",
    "\n",
    "for i in range(epochs):\n",
    "    y_pred = model(X_train)\n",
    "    loss = critation(y_pred, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % eval_interval == 0:\n",
    "        print(f'iter: {i+1} loss={loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "305af1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1000, loss=0.25615429878234863\n",
      "Iter: 2000, loss=0.23632727563381195\n",
      "Iter: 3000, loss=0.2280023992061615\n",
      "Iter: 4000, loss=0.22484996914863586\n",
      "Iter: 5000, loss=0.2225530743598938\n",
      "Test MSE: 0.6873\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = fetch_california_housing(return_X_y=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = torch.tensor(scaler.fit_transform(data[0]), dtype=torch.float)\n",
    "y = torch.tensor(data[1], dtype=torch.float)\n",
    "\n",
    "# defining the shape\n",
    "n, n_features = X.shape\n",
    "\n",
    "# spliting the dataset\n",
    "sps = int(n*.8)\n",
    "X_train = X[:sps]\n",
    "X_test = X[sps:]\n",
    "y_train = y[:sps]\n",
    "y_test = y[sps:]\n",
    "\n",
    "# model config\n",
    "learning_rate = 1e-2\n",
    "epochs = 5000\n",
    "\n",
    "# building our MLP\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ly1 = nn.Linear(n_features, 64)\n",
    "        self.ly2 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, X):\n",
    "        x= self.relu(self.ly1(X))\n",
    "        x = self.ly2(x)\n",
    "        return x \n",
    "    \n",
    "\n",
    "\n",
    "# initialing our NN\n",
    "model = MLP()\n",
    "\n",
    "# loss and optimizers\n",
    "critation = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for k in range(epochs):\n",
    "    y_pred = model(X_train).squeeze()\n",
    "    loss = critation(y_pred, y_train)\n",
    "\n",
    "    # applying optimizer\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (k+1) % 1000 == 0:\n",
    "        print(f'Iter: {k+1}, loss={loss.item()}')\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test).squeeze()\n",
    "\n",
    "mse = torch.mean((y_pred - y_test)**2).item()\n",
    "rmse = mse**0.5\n",
    "\n",
    "print(f\"Test MSE: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "61bbbd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight vector (including bias):\n",
      "tensor([[ 2.0686],\n",
      "        [ 0.8296],\n",
      "        [ 0.1188],\n",
      "        [-0.2655],\n",
      "        [ 0.3057],\n",
      "        [-0.0045],\n",
      "        [-0.0393],\n",
      "        [-0.8998],\n",
      "        [-0.8705]])\n",
      "Closed-form Test MSE: 0.4753\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load data\n",
    "X_np, y_np = fetch_california_housing(return_X_y=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_np)\n",
    "\n",
    "X = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y = torch.tensor(y_np, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# Add bias column (intercept)\n",
    "ones = torch.ones((X.shape[0], 1))\n",
    "X_bias = torch.cat([ones, X], dim=1)\n",
    "\n",
    "# Normal Equation: theta = (X^T X)^(-1) X^T y\n",
    "theta = torch.inverse(X_bias.T @ X_bias) @ X_bias.T @ y\n",
    "\n",
    "print(\"Weight vector (including bias):\")\n",
    "print(theta)\n",
    "\n",
    "# Split data (same 80/20 split as before)\n",
    "sps = int(0.8 * X.shape[0])\n",
    "X_test = X_bias[sps:]\n",
    "y_test = y[sps:]\n",
    "\n",
    "# Predict\n",
    "y_pred = X_test @ theta\n",
    "\n",
    "# Compute MSE\n",
    "mse = torch.mean((y_pred - y_test)**2).item()\n",
    "print(f\"Closed-form Test MSE: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "13abe560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.4947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f\"Test MSE: {mean_squared_error(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb83dd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "my calculation: 85\n",
      "[72, 6, 6, 1]\n",
      "85\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(12, 6),\n",
    "    nn.Linear(6, 1),\n",
    ")\n",
    "\n",
    "\n",
    "# if there is no bias, no need for adding \n",
    "print(len(list(net.parameters())))\n",
    "print(f\"my calculation: {(12*6+6) + (6*1+1)}\")\n",
    "\n",
    "res = [p.numel() for p in net.parameters() if p.requires_grad]\n",
    "\n",
    "print(res)\n",
    "print(sum(res))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8d8a89f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.randn(2, 3, 3).numel() == 2*3*3, \"failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2a7d83f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.0391, -0.2416, -1.7920],\n",
       "         [ 0.4204, -0.6147,  0.2263],\n",
       "         [ 1.5441, -1.3303, -1.3287],\n",
       "         [-0.4162,  0.4767,  0.6769]],\n",
       "\n",
       "        [[ 0.2300, -0.2331,  2.1463],\n",
       "         [ 0.9718, -0.3368, -0.7853],\n",
       "         [-0.7826, -0.4238,  0.0660],\n",
       "         [ 2.2129, -0.8283,  1.6527]],\n",
       "\n",
       "        [[ 0.7336, -0.6972,  0.3850],\n",
       "         [-0.0322,  1.0844,  0.8005],\n",
       "         [ 0.1479, -1.4065,  0.3000],\n",
       "         [-1.6717,  1.2735,  0.4505]]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3, 4, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
